{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/rnbkp5ubgk82ocu/CSL.zip?dl=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CSL(150):\n",
      "======================\n",
      "Number of graphs: 150\n",
      "Number of features: 0\n",
      "Number of classes: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting tmp/gnn_benchmark/CSL/raw/CSL.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = GNNBenchmarkDataset(root='tmp/gnn_benchmark', name='CSL')\n",
    "\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very basic generation of a graphon\n",
    "\n",
    "This is much simpler than the method described in the paper, only here as a sorta placeholder/demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 1., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       [1., 1., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjaency_matrix = to_dense_adj(data.edge_index).numpy().squeeze()\n",
    "adjaency_matrix = nx.to_numpy_array(G)\n",
    "adjaency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "clustering = SpectralClustering(n_clusters=k, affinity='precomputed').fit(adjaency_matrix)\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphon = np.zeros((k, k))\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        nodes_i = np.where(labels == i)[0]\n",
    "        nodes_j = np.where(labels == j)[0]\n",
    "        # print(nodes_i, nodes_j)\n",
    "        # raise ValueError('TODO: implement this')\n",
    "        subgraph = G.subgraph(nodes_i.tolist() + nodes_j.tolist())\n",
    "        graphon[i, j] = nx.density(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanford-cs224w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
