Title: IBM How to use DataStage Parallel environment variable APT_PHYSICAL_DATASET_BLOCK_SIZE - United States

Text:
BLOCK_SIZE TECHNOTE (FAQ)

QUESTION
 When setting the APT_PHYSICAL_DATASET_BLOCK_SIZE and APT_DEFAULT_TRANSPORT_BLOCK_SIZE 
environment variables to the same size as the BLOB column is defined in the table schema, we run into errors. 
However, when we increase the environment variables by 1024 bytes, the job runs without any problems. 
What is causing the job to fail when we set them to the same size? 

CAUSE
The block size has to be greater than the largest row. If the entire record is too large for the block, then the job will fail. 

ANSWER
Since the blob is not the only column in the row , the max block size has to be able to account for all the columns. 
1. The APT_PHYSICAL_DATASET_BLOCK_SIZE and APT_DEFAULT_TRANSPORT_BLOCK_SIZE environment variables should only be increased on the jobs that require them.
2. Unnecessary large block sizes can impact performance