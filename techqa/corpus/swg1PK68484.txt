Title: IBM PK68484: MQ QUEUE CONNECTION FACTORY (QCF) HAS MQ CLIENT POOLING ENABLED BY DEFAULT - United States

Text:
 SUBSCRIBE
You can track all active APARs for this component.



APAR STATUS
 * CLOSED AS DOCUMENTATION ERROR.
    
   
   

ERROR DESCRIPTION
 *  Both WebSphere Application Server and the MQ Client provide
   connection pooling to potentially improve performance. Both
   products have included this capability because it is possible
   that each product will be used independently from the other
   product.
   
      The configuration parameter that sets this in the QCF
   configuration of the resources.xml file is
   useConnectionPooling="true"
   
   WebSphere Application Server supports other Java Message
   Service (JMS) providers. The MQ client can be used with other
   application servers or with a Java client.
   
   In this scenario, a firewall or router exists between
   WebSphere Application Server with the MQ client and the MQ
   Server that closes connections after a certain period of idle
   time. The MQ client might enter into looping behavior if the
   firewall closes a connection in the MQ client pool. In this
   case, WebSphere Application Server does not seem
   responsive. The problem that exists prevents WebSphere
   Application Server from getting a connection from the MQ Queue
   Connection Factory (QCF) connection pool. Moreover, the
   getConnection method request does not return; the application
   is "stuck" at this statement. A message does not exist in the
   WebSphere Application Server logs. In time, after all of the
   connection handles are assigned to application threads
   trying to get a connection, J2CA0020E and J2CA0045E errors will
   be logged due to a ConnectionWaitTimeoutException exception.
   
   This problem is more likely to happen if there has been a
   prolonged period of inactivity on an application.  The prolonged
   period of inactivity allows the firewall to close idle
   connections, which are not removed from the MQ client connection
   pool.
   
   A trace with the WAS.j2c=all event enabled show that
   there is a reserve() call driven by the getConnection API
   call.  This call never completes.
   
   The MQ client code enters into a loop in which it tries to
   clean up an existing connection. However, because the firewall
   has closed the connection, it cannot connect to the MQ Server
   on the connection to clean up, but it continues to try to
   connect. The MQ client calls MQOpen to complete the JMS
   createConnection.
   
   Every 10 seconds, you see an exception, such as a  InterruptedIO
   Exception. It retries 15 times, with each successive retry
   having a lower and lower timeout. It is interrupted after 10
   seconds in each case, which leads to a
   com.ibm.mq.MQInternalCommunications timed out exception.
   
   As a result of the MQOpen that fails with cc,rc=2, 2009,
   the MQ client then tries to disconnect this connection; this
   fails with cc,rc = 2, 2018.
   .
   An MQOpen is attempted again and this process repeats itself.
   [5/15/08 8:03:55:334 EDT] 00001438 JMS_WASTraceA >
   MQSESSIONClient MQOPEN Entry
   
   In summary, the issue is that the MQ client connection pooling
   is redundant and interferes with the WebSphere Application
   Server connection pooling.  The connection pool for WebSphere
   Application Server can be empty, but the MQ client connection
   pool holds open connections to the MQ Server.  When an attempt
   is made to get a new connection, the MQ client tries to use one
   of its pooled connections. However, because the firewall has
   closed the connection, the MQ client gets a SocketException
   when it tries to use it. To tune the connection pool for
   WebSphere Application Server so that it closes the connection
   before the firewall does, set the minConnections value to 0.
   Set the UnusedTimeout value to be less than the firewall
   timeout value. Set the reap timeout value so that it is often
   enough that WebSphere Application Server has a couple of
   opportunities to close the connection between the expiration of
   the UnusedTimeout value and the firewall closing the connection.
   
   The Information Center needs to document that you need to
   deselect the "Enable MQ client connection pooling" option
   for WebSphere Application Server because it has the potential
   to interfere with the WebSphere Application Server connection
   pooling.
   
   
    
   
   

LOCAL FIX
 *  Disable the MQ client connection pooling from the WebSphere
   Administrative Console.
   
   Change the QCF configuration to uncheck the 'enable mq
   connection pooling' box in the qcf definitions panel.
   
   http://publib.boulder.ibm.com/infocenter/wasinfo/v6r0/index.jsp?
   topic=/com.ibm.websphere.nd.doc/info/ae/ae/tmj_mqcon.html [http://publib.boulder.ibm.com/infocenter/wasinfo/v6r0/index.jsp?topic=/com.ibm.websphere.nd.doc/info/ae/ae/tmj_mqcon.html]
   <http://publib.boulder.ibm.com/infocenter/wasinfo/v6r0/index.jsp
   ?topic=/com.ibm.websphere.nd.doc/info/ae/ae/tmj_mqcon.html>
   
   APAR PK46356 was included in WebSphere AppServer 6.0.2.23 and
   6.1.0.11, it corrected some problems with how the 'enable mq
   connection pooling' checkbox worked.  Prior to these versions,
   it is recommended to change the
   
   mqjms.pooling.threshold  to 0 connection and
   
   mqjms.pooling.timeout to 1800000 ms.
   
   This will have the effect of disabling the MQ client connection
   pooling, since it will set the number of pooled connections to
   0.
   
   
    
   
   

PROBLEM SUMMARY
 *  ****************************************************************
   * USERS AFFECTED:  This APAR affects users of WebSphere        *
   *                  Application Server Version 6.0 and 6.1,     *
   *                  who interoperate with WebSphere MQ and who  *
   *                  have WebSphere MQ Client pooling enabled    *
   *                  by default.                                 *
   ****************************************************************
   * PROBLEM DESCRIPTION: Connections are shut down by the        *
   *                      firewall rather than cleaned up by      *
   *                      the connection pool if the following    *
   *                      conditions are true:                    *
   *                      -A firewall is being used that closes   *
   *                      idle connections.                       *
   *                      -The combined unused timeout value      *
   *                      that is configured in the connection    *
   *                      pool for the application server and     *
   *                      the mqjms.pooling.timeout value,        *
   *                      which is configured in WebSphere MQ     *
   *                      connection pooling, is greater than     *
   *                      the idle timeout configured on the      *
   *                      firewall                                *
   *                                                              *
   *                      This APAR is to document this           *
   *                      situation in the Information Center     *
   *                      and to advise users on how to avoid     *
   *                      disconnection by leaving the aged       *
   *                      timeout for connection pools set to     *
   *                      the default value of 0.                 *
   ****************************************************************
   * RECOMMENDATION:                                              *
   ****************************************************************
   The following topics will be changed:
   
   - Configuring WebSphere MQ connection pooling
   - WebSphere MQ connection factory settings
   - WebSphere MQ topic connection factory settings
   - WebSphere MQ queue connection factory settings
   
   
    
   
   

PROBLEM CONCLUSION
 *  For the topic Configuring WebSphere MQ connection pooling, the
   following note will be added:
   "If a firewall is being used that closes idle connections, the
   total of the unused timeout configured on the WebSphere
   Application Server connection pool and the
   mqjms.pooling.timeout configured in WebSphere MQ connection
   pooling must be less than the idle timeout configured on the
   firewall to allow connections to be cleaned up by the
   connection pools, rather than being terminated by the firewall."
   
   For each of the following topics, a reference was added to
   Configuring WebSphere MQ connection pooling:
   - WebSphere MQ connection factory settings
   - WebSphere MQ topic connection factory settings
   - WebSphere MQ queue connection factory settings
   
   
    
   
   

TEMPORARY FIX

COMMENTS

APAR INFORMATION
 * APAR NUMBER
   PK68484
   
   
 * REPORTED COMPONENT NAME
   WEBSPH APP SERV
   
   
 * REPORTED COMPONENT ID
   5724J0800
   
   
 * REPORTED RELEASE
   60A
   
   
 * STATUS
   CLOSED DOC
   
   
 * PE
   NoPE
   
   
 * HIPER
   NoHIPER
   
   
 * SPECIAL ATTENTION
   NoSpecatt
   
   
 * SUBMITTED DATE
   2008-07-02
   
   
 * CLOSED DATE
   2008-08-21
   
   
 * LAST MODIFIED DATE
   2011-02-10
   
   

 * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:
   
   
   
 * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:
   
   
   

FIX INFORMATION

APPLICABLE COMPONENT LEVELS