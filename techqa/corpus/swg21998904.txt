Title: IBM Debugging Streams Java Operator Congestion - United States

Text:
 TECHNOTE (FAQ)

QUESTION
 How can you debug no tuple flow due to congestion in a Streams Java Operator? 

ANSWER
The following is an example of a small application which has a Beacon feeding into a java primitive operator. One tuple is allowed to flow through then it sleeps. Op_2 is the problem operator.

The console Application Dashboard looks like this. 

 * 
 * 



All pe's remain healthy:  * 
 * $ streamtool lspes -d test411 -i testinst
   Instance: testinst
   Id State RC Healthy Resource PID JobId JobName Operators
   15 Running - yes xxxxxxx.ibm.com 12539 5 Main_5 Beacon_1
   16 Running - yes xxxxxxx.ibm.com 
 * 12569
 * 5 Main_5 Op_2
   17 Running - yes xxxxxxx.ibm.com 12572 5 Main_5 Custom_3


Follow these steps to identify the offending code: 
 1. Issue a kill -3 on the problem pid 3 times at 20 second intervals.
    
    $kill -3 12569
    
 2. Find the javacore under streamsadmin home .streams directory
    
    $ cd /home/streamsadmin/.streams
    $ find . -name 'javacore*'
    ./var/Streams.sab_DLZ-test411-testinst/293f6a2f-15fe-4078-ba88-6ed42d135479/currentWorkingDir/5/javacore.20170211.112104.12569.0001.txt
    
    Note. This directory and the javacore will go away when the job is cancelled, save it to another location.
    
 3. View the javacore in your editor and search for the 'Thread Details' section.
    Next search for <YourClass>.proccess to identify the hang.
    
    3XMTHREADINFO "Thread-15" J9VMThread:0x0000000001B75500, j9thread_t:0x00007FCCEC000910, java/lang/Thread:0x00000000FFF201C0, state:CW, prio=5
    3XMJAVALTHREAD (java/lang/Thread getId:0x1D, isDaemon:true)
    3XMTHREADINFO1 (native thread ID:0x319B, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000401)
    3XMTHREADINFO2 (native stack address range from:0x00007FCCFABFE000, to:0x00007FCCFB5FF000, size:0xA01000)
    3XMCPUTIME CPU usage total: 0.005598060 secs, current category="Application"
    3XMHEAPALLOC Heap bytes allocated since last GC cycle=55264 (0xD7E0)
    3XMTHREADINFO3 Java callstack:
    4XESTACKTRACE at java/lang/Thread.sleep(Native Method)
    4XESTACKTRACE at java/lang/Thread.sleep(Thread.java:909)
    4XESTACKTRACE at application/Congest.process(Congest.java:107)
    4XESTACKTRACE at com/ibm/streams/operator/internal/runtime/api/OperatorAdapter.processTuple(OperatorAdapter.java:1554)
    4XESTACKTRACE at com/ibm/streams/operator/internal/runtime/api/OperatorAdapter$1.tuple(OperatorAdapter.java:829)
    4XESTACKTRACE at com/ibm/streams/operator/internal/runtime/api/OperatorAdapter$1.tuple(OperatorAdapter.java:822)
    4XESTACKTRACE at com/ibm/streams/operator/internal/ports/SwitchingHandler$Alternate.tuple(SwitchingHandler.java:162)
    4XESTACKTRACE at com/ibm/streams/operator/internal/network/DeserializingStream.tuple(DeserializingStream.java:76)
    4XESTACKTRACE at com/ibm/streams/operator/internal/network/DeserializingStream.processRawTuple(DeserializingStream.java:65)



If the first core's thread does not contain a blocking call, examine the remaining core files for a larger loop that may be an issue. 

There is a graphical viewing tool on developerworks which can be very helpful. 
https://www.ibm.com/developerworks/community/groups/service/html/communityview?communityUuid=2245aa39-fa5c-4475-b891-14c205f7333c [https://www.ibm.com/developerworks/community/groups/service/html/communityview?communityUuid=2245aa39-fa5c-4475-b891-14c205f7333c] 

The pe stdouterr files can also be helpful if detailed logging is enabled. 

Attached are the SPL, Java code and the tarred Streams Studio project for the sample, which you can import into Streams Studio. 

Main.spl [/support/docview.wss?uid=swg21998904&aid=3]Main.spl [/support/docview.wss?uid=swg21998904&aid=2] Congest.java [/support/docview.wss?uid=swg21998904&aid=5]Congest.java [/support/docview.wss?uid=swg21998904&aid=4] TestCongestion.tar [/support/docview.wss?uid=swg21998904&aid=7]TestCongestion.tar [/support/docview.wss?uid=swg21998904&aid=6]