Title: IBM BigInsights: How to resolve out of memory errors while running commands on spark shell? - United States

Text:
 TECHNOTE (FAQ)

QUESTION
 IBM BigInsights: How to resolve out of memory errors while running commands on spark shell? 

CAUSE
Spark uses heap memory extensively for processing if there is no sufficient memory available for processing the job and spark shell terminates.

ANSWER
When spark shell terminates with following error 

16/06/16 16:38:05 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space

Restart spark shell with higher executor and driver memory size as shown in following example

spark-shell --executor-memory 2000M --driver-memory 2000M