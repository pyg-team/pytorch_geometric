Title: IBM DataStage job using Grid Toolkit fails with java submit error for GenConfig. - United States

Text:
 TECHNOTE (TROUBLESHOOTING)

PROBLEM(ABSTRACT)
 DataStage job using Grid Toolkit fails due to java error:

Message: <Dynamic_grid.sh>Error: Job error, submit error. invoking GenConfig... Please check Java is available on the compute nodes 

Message: Parallel job reports failure (code 256) 


CAUSE
The cause of the java failure should be listed in javacore file written at time of job failure. In this case the issue was due to the Java virtual machine (JVM) reverting to system default limit for number of threads (1024) which was insufficient for the number of jobs running.

RESOLVING THE PROBLEM
At the time of failure, a javacore file should be written to the project directory. Find the javacore file which matches time of job failure and find the cause at start of file, for example:
Dump Event "systhrow" (00040000) Detail "java/lang/OutOfMemoryError" "Failed to create a thread: retVal -1073741830, errno 11" received 

In the case of the above error, we see both a memory error and a thread start failure. For grid toolkit the java memory usage is typically very low and thus the more likely cause is that nproc limit (ulimit -u) for maximum number of threads per user was reached.



 * Find the section showing limits in javacore file, i.e.
   2CIUSERLIMIT RLIMIT_DATA unlimited unlimited
   2CIUSERLIMIT RLIMIT_FSIZE unlimited unlimited
   2CIUSERLIMIT RLIMIT_NOFILE 8192 8192
   2CIUSERLIMIT RLIMIT_NPROC 1024 514989
   2CIUSERLIMIT RLIMIT_RSS unlimited unlimited
   
   If the NPROC limit is 1024, that is likely the cause of the error as that number is far too low on a system with many jobs running under 1 userid. In that situation, have your Unix administrator look in the /etc/security/limits.conf file to see current soft/hard nproc limits. Check global settings, root settings, and also defaults for user running the job. Increase the limit to at least 10000. Then look in the dsenv script in the /opt/IBM/InformationServer/Server/DSEngine directory to confirm it is not using a lower limit. You can also use this file to set limit to 10000 with the command:
   ulimit -u 10000
   
   It is important on some environments such as RedHat Linux 6 to set not only the limits within DataStage but also the system default global limits due the way that calling java from script can cause it to revert to using system default limits.
   
   Additionally, if you are using RedHat Linux 6 or certain other linux levels, you may have one more file to change. Look in directory /etc/security/limits.d for any files. If that directory contains any conf files such as 90-nproc.conf, then it can override system default limits. This file usually contains a global default nproc limit, i.e.: 
   * soft nproc 1024
   
   Change that line to 10000 (or higher) and save change. After making the change to this file, and any other files in that directory which change nproc setting, you will need to reboot the machine for change to take effect. 
   
 * If the above does not resolve the issue, examine the memory related limits in javacore file.
   
   Scroll down the javacore file until you see section similar to the following listing memory usage in hex:
   1STHEAPFREE Bytes of Heap Space Free: 3A02A8 
   1STHEAPALLOC Bytes of Heap Space Allocated: 400000 
   
   Also, search the file for any occurrence of "xmx" parameter as that will control maximum JVM size if defined. 
   
   If the Heap space allocated number matches either the max JVM size (if xmx defined) or is at size limit shown for data or rss limits, then the JVM may not be able to grow larger than its current size, thus if the bytes free in heap is smaller than the amount of memory job needs, it will be unable to request more and java memory error occurs. In that situation you can increase ulimits. It is not usually neccessary to increase or set an xmx value for Grid Toolkit java processes since its memory requirements are small.