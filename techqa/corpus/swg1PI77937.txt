Title: IBM PI77937: MIGRATING FROM BI 3.X TO BI 4.X CAN CAUSE UNEXPECTED ISSUES DUE TO HIVE-6681 - United States

Text:
 SUBSCRIBE TO THIS APAR
By subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.

Notify me when this APAR changes.

Notify me when an APAR for this component changes.



APAR STATUS
 * CLOSED AS PROGRAM ERROR.
    
   
   

ERROR DESCRIPTION
 *  Migrating Big SQL tables from BI 3.x to BI 4.x requires the
   execution of the HCAT_SYNC_OBJECTS stored procedure to import
   the tables from Hive after the Big SQL Service is installed on
   IOP or HDP.
   
   Big SQL uses the COMMENT field in the Hive Metastore to store
   some additional information about the table. For example, if a
   column is defined with a "NOT NULL" constraint in Big SQL, this
   meta data is kept in the COMMENT field in Hive.
   
   In Hive 0.11.0, 0.12.0, as roles and the binominal mappings are
   stored in column comments
   (https://issues.apache.org/jira/browse/HIVE-6681), these
   comments will be replaced with 'from deserializer".
   
   In Big SQL 3.x the VARCHAR data type is stored as a STRING in
   the Hive. When a table is created with a VARCHAR column, in the
   Hive Metastore the COMMENT field is used to indicate that the
   column is actually a VARCHAR in Big SQL. However due to this
   Jira, this information is lost.
   
   For example if the intention is to create a table such as:
   
   CREATE HADOOP TABLE TAB1(
       "COL1" VARCHAR(2) NOT NULL , . . . )
   STORED AS PARQUETFILE;
   
   
   The expected hive metadata for this bigsql table should be:
   
   COMMENT                                           COLUMN_NAME
     TYPE_NAME          INTEGER_IDX
   ----------------------------------------------------------------
   ----------------------------------------------------------------
   --------
   /*@type=varchar(2),notnull=true*/    col1
   string                        0
   
   But in reality due to this Jira the following is stored in the
   Hive Metastore :
   
   COMMENT                                           COLUMN_NAME
     TYPE_NAME          INTEGER_IDX
   ----------------------------------------------------------------
   ----------------------------------------------------------------
   --------
   from deserializer                                  col1
              string                        0
   
   
   Note that because the comment is replace with "FROM
   DESERIALIZER" , Big SQL will not know that the intention is to
   create a varchar(2) and will instead think that it is a varchar
   of length 32K. Also the "NOT NULL" constraint is also lost
   which could also cause some performance issues. A describe on
   the table reveals that it is using a 32K varchar
   
   DESCRIBE TABLE BIGSQL.TAB1
                                   Data type
   Column
   Column name                     schema    Data type name
   Length     Scale Nulls
   ------------------------------- --------- -------------------
   ---------- ----- ------
   COL1                        SYSIBM    VARCHAR
   32672     0 Yes
   
   
    
   
   

LOCAL FIX
 *  This issue is fixed in Hive 0.13. After moving from Big SQL v3
   to Big SQL v4, run the following steps to determine if this is
   an issue:
   
   1)From Hive, <describe extended tab1> on all tables and search
   for "FROM DESERIALIZER" in the COMMENT fields.
   
   2) If tables are found with this then create a parallel table
   for each offending table in Big SQL v4. For example
   
   CREATE HADOOP TABLE TAB2(
       "COL1" VARCHAR(2) NOT NULL ,
   . . . )
   STORED AS PARQUETFILE;
   
   3) Populate this new BigSQL table with data from the offending
   BigSQL table. There are two ways to do that. One is to distcp
   the old hive table data to the new hive table data location. If
   this table is a partitioned table, repair the metadata of the
   new table after the distcp operation. The other is the use the
   "insert into <new_table> select * from <old_table>" command.
   
   4) Verify that the new BigSQL table has the same table row
   count and same table contents as the old BigSQL table.
   
   5) Rename the old BigSQL table to a backup BigSQL table and
   rename the new BigSQL table to the old BigSQL table.
   
   
    
   
   

PROBLEM SUMMARY
 *  See error description.
   
   
    
   
   

PROBLEM CONCLUSION
 *  The problem is fixed in Version 4.3 and later fix packs.
   
   
    
   
   

TEMPORARY FIX

COMMENTS

APAR INFORMATION
 * APAR NUMBER
   PI77937
   
   
 * REPORTED COMPONENT NAME
   INFO BIGINSIGHT
   
   
 * REPORTED COMPONENT ID
   5725C0900
   
   
 * REPORTED RELEASE
   420
   
   
 * STATUS
   CLOSED PER
   
   
 * PE
   NoPE
   
   
 * HIPER
   NoHIPER
   
   
 * SPECIAL ATTENTION
   NoSpecatt / Xsystem
   
   
 * SUBMITTED DATE
   2017-03-09
   
   
 * CLOSED DATE
   2017-04-07
   
   
 * LAST MODIFIED DATE
   2017-04-07
   
   

 * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:
   
   
   
 * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:
   
   
   

MODULES/MACROS
 *  n/a
   
   
    
   
   

FIX INFORMATION
 * FIXED COMPONENT NAME
   INFO BIGINSIGHT
   
   
 * FIXED COMPONENT ID
   5725C0900
   
   

APPLICABLE COMPONENT LEVELS
 * R430 PSY
   UP