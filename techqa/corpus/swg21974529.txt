Title: IBM Best Practices for Preventing LOG.SQLT from Growing Too Quickly - United States

Text:
 TECHNOTE (TROUBLESHOOTING)

PROBLEM(ABSTRACT)
 Log.sqlt is a database where information about the URLs that have been processed for a given collection is stored. This database is essential for adding to or updating indexed data, refreshes, annotations (tagging, comments, rating, follows, etc.), and also for synchronized distributed indexing.
This Technote explains best practices for preventing log.sqlt from growing too large quickly. 

CAUSE
The log.sqlt file commonly grows large because synchronized distributed indexing is being used improperly. All configured synchronized distributed indexing clients should be running and connected before any data is ingested. If clients are configured but not running, the master will persist client updates to the log.sqlt. After the client is finally synchronized, the space in log.sqlt is not recovered. Note that it is possible to recover this space manually (see below).

ENVIRONMENT
Microsoft Windows or Linux. This issue tends to manifest with the log.sqlt and cache.sqlt files in the Watson Explorer Foundational Components context with errors appearing on the overview page of a collection during refresh or crawl operations such as (Windows): SQL operation [commit;] could not be executed on database [D:\lab\WEX\Engine\data\search-collections\659\collection-name\crawl1\log.sqlt]:[disk I/O error]. These messages will also be reported to the system reporting database.

DIAGNOSING THE PROBLEM
One symptom is that log.sqlt is larger than the ingested data size, for example, a 200 GB log.sqlt with a data index of only 300 MB. 

In addition, on Windows, large and/or frequently written files can run into NTFS limitations. As an example, the FAL Fragmentation limit for NTFS is around 1.5 million fragments. If this limit is approached or exceeded, attempts to interact with the log.sqlt can fail with Disk I/O errors reported by the operating system. Messages such as the following can be reported to the Windows Event logs : 

 * Insufficient system resources exist to complete the requested service 
 * The requested operation could not be completed due to a file system limitation


See below for more details and possible diagnostic steps 

RESOLVING THE PROBLEM
 

 * The log.sqlt is created (or re-created) anytime a new crawl is done. If unnecessary data has accumulated in the current log.sqlt, a new crawl will "start from scratch." 
 * If you are planning on using synchronized distributed indexing, you can perform your initial ingestion without distributed indexing clients configured at all. Once the initial ingestion on the ‘master’ system is complete you can then add the desired synchronized distributed indexing client configuration - one client system at a time - and then rebase each client in turn. This will minimize any potential for client configuration issues to cause client updates to be persisted to the log.sqlt on the master. 
 * It may be possible to 'shrink' a log.sqlt using the sqlite vacuum command. This command essentially creates a new log.sqlt, and copies data from the existing log.sqlt into the new copy. This can result in a smaller log.sqlt file if there are a lot of unused rows in the existing log.sqlt. Note that this operation is non-recoverable, meaning once initiated it can not be rolled back. A vacuum operation should be attempted only if the crawler is stopped and no ingestion activity (including DI updates, API enqueues, and end-user submitted annotations) are underway (or are scheduled), and after a full backup of the log.sqlt is taken. Using velocity-shutdown, or setting the desired collection to read-only mode are two ways to ensure that the collection is not active.


Microsoft Windows Considerations for Large Files 
On Microsoft Windows, large and/or frequently written files can run into NTFS limitations. One such limitation is FAL Fragmentation limit for NTFS is around 1.5 million fragments. If this limit is approached or exceeded, attempts to interact with the log.sqlt can fail with Disk I/O errors reported by the operating system. Messages such as the following can be reported to the Windows Event logs :  * Insufficient system resources exist to complete the requested service 
 * The requested operation could not be completed due to a file system limitation


The articles in the "Related information" list provide more insight on how this issue arises with NTFS file systems. The contig utility can be used to examine the fragmentation of the FAL, and for files with many fragments the following steps can be used to reduce the FAL fragmentation. Also, much like vacuum, this operation should be attempted only if the crawler is stopped and no ingestion activity (including DI updates, API enqueues, and end-user submitted annotations) is underway or scheduled, and after a full backup of the log.sqlt is taken. Using velocity-shutdown, or setting the desired collection to read-only mode are two ways to ensure that the collection is not active.  1. Make a copy of the database on a different drive that has sufficient space. IMPORTANT: Do not create a copy of the database on the same drive because this file needs to be written contiguously to the new drive. Copying the file defrags the file for you. 
 2. Rename the original version of the database file (this renamed file can be deleted at a later date after confirming a reduction in fragmentation). 
 3. Copy the new database file back to the original location. 
 4. Bring the collection back up and verify functionality.


Microsoft does provide guidance on NTFS and large files, recommending that drives which will host large files be formatted with the /L switch (see the "Related information" list). RELATED INFORMATION
 How fragmentation on incorrectly formatted NTFS volumes [http://blogs.technet.com/b/mikelag/archive/2011/02/09/how-fragmentation-on-incorrectly-formatted-ntfs-volumes-affects-exchange.aspx]
A heavily fragmented file in an NTFS volume may not gro [https://support.microsoft.com/en-us/kb/967351?wa=wsignin1.0]
The Four Stages of NTFS File Growth pt.1 [http://blogs.technet.com/b/askcore/archive/2009/10/16/the-four-stages-of-ntfs-file-growth.aspx]
The Four Stages of NTFS File Growth pt.2 [http://blogs.technet.com/b/askcore/archive/2015/03/12/the-four-stages-of-ntfs-file-growth-part-2.aspx]
Contig Utility [https://technet.microsoft.com/en-us/sysinternals/bb897428.aspx]
SQLite Vacuum [https://sqlite.org/lang_vacuum.html]
"ERROR_FILE_SYSTEM_LIMITATION" when a write operation i [https://support.microsoft.com/en-us/kb/2891967]