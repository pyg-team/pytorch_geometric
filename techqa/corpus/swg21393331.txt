Title: IBM Improving I/O performance on z/OS - United States

Text:
WTX z/OS performance TECHNOTE (FAQ)

QUESTION
 Is there a way to improve elapsed time performance with WebSphere® Transformation Extender (WTX) on z/OS. 

CAUSE
Traditionally the WTX z/OS batch features (Platform API and Command Server) have used z/OS BSAM datasets for work file I/O. These datasets are accessed as byte stream files. WTX needs to position (seek) to any arbitrary byte with in the file. Because z/OS native datasets are record oriented the process to randomly seek is expensive. Especially when these datasets are multi-volume.

ANSWER
Use the UNIX System Services Temporary File System (TFS). TFS is in memory file system that can utilize “above the 2GB bar” 64 bit storage. Because TFS is an in memory file system there are no EXCP issued for the I/O request. In the WTX lab it has been determined that using TFS can improve elapsed time performance by up to almost 50% depending on the use case. 

To use TFS there needs to be enough real storage and page space available to satisfy aggregate size for the work files that are directed to the file system. If the z/OS server/LPAR is limited in the amount of real storage available to it, you should consider using the USS zSeries File System (zFS). Using zFS will also result in significantly lower elapsed run times. The only issue with using zFS is you need to ensure that there is enough disk space available and allocated to satisfy the the size requirement for the work files. 

The specification of these type of work files are done via the DD cards defined in the JCL so you can mix and match any of the three file systems. If there is one specific work file that is reporting high EXCP that single file can be directed to TFS or zFS. If the resources are available all of the work files should be directed to TFS.

Example on how to direct a work file to TFS or zFS:

//SYSTMP01 DD PATH='/tfstemp/sysh001.tmp', 
// PATHDISP=(DELETE), 
// PATHOPTS=(ORDWR,OCREAT), 
// PATHMODE=(SIRWXU,SIRWXG,SIROTH) 

There is one caveat using TFS/zFS versus traditional z/OS temporary datasets. When using z/OS temporary datasets, the actual dataset name is created dynamically. Using TFS/zFS the directory name needs to exist and the file name needs to be unique. Each WTX job that may be run concurrently to another will need to have a unique name. That can be accomplished by either adding a sub-directory for the file path. Example: 

Job A:

//SYSTMP01 DD PATH='/tfstemp/work1/sysh001.tmp',

Job B:

//SYSTMP01 DD PATH='/tfstemp/work2/sysh001.tmp',

Alternatively the use of a JCL symbol in the file name could be used. Example: 

Job A:

// SET INSTID=1 Instance ID for this job
.
.
//SYSTMP01 DD PATH='/tfstemp/sysh001.tmp_&INSTID.', 

Would result in the file name:

/tfstemp/sysh001.tmp_1 

Job B:

// SET INSTID=2 Instance ID for this job
.
.
//SYSTMP01 DD PATH='/tfstemp/sysh001.tmp_&INSTID.', 

Would result in the file name:

/tfstemp/sysh001.tmp_2 

If the job is under control of a job scheduler, another option would be to use a variable supplied by the scheduler. The job number or a time stamp that represents the time down to a hundredth of a second could be added to the file name. Example:

/tfstemp/sysh001.tmp_&JOBNUM.

/tfstemp/sysh001.tmp_00123456

Another thing to note is that the use of TFS or zFS will have marginal impact to the CPU time. The impact is trivial compared to the benefit to the reduction in elapsed time.

To learn more about configuring either TFS or zFS refer to the: 
GA22-7800 - z/OS UNIX System Services Planning manual

To learn more about using TFS and zFS file in JCL or the use of symbolic variables refer to the:
SA22-7597 - z/OS MVS JCL Reference





PRODUCT ALIAS/SYNONYM
 Ascential DataStage TX Mercator transformation Extender