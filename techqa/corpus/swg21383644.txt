Title: IBM Web Content Management crawler FAQ - United States

Text:
 TECHNOTE (FAQ)

QUESTION
 This document addresses several frequently asked questions about the Web Content Management crawler. 

ANSWER
Question 1:
How does the Web Content Management crawler work? Is it possible to reduce the overall crawling time? 

Answer 1:
The Web Content Management crawler works in two phases: 

 1. It downloads the seed list from the Web Content Management server to extract the URLs to crawl. 
 2. It downloads the content of each URL in the seed list, or the pages that are linked from the URL that is listed in the seed list and found in the same Web Content Management library.


If you want to reduce the time it takes to crawl the Web Content Management library, you must measure how long it takes to download the seed list from the Web Content Management server and how long it takes to download the content itself. You can check the crawler audit log file in the ES_NODE_ROOT/logs/audit/ collection_ID.crawler_ID_<date>.log file or gather the detailed crawler trace data. 

In most cases, downloading the seed list that is published by the Web Content Management server takes more time than downloading the actual content. The Web Content Management crawler cannot reduce the time it takes to download the seed list because the Web Content Management server generates and publishes the seed list. To improve performance in this phase, tune the Web Content Management server. 

If the Web Content Management server has enough system resources to receive continuous fetch requests from the Web Content Management crawler, modify the value of the Time to wait between retrieval requests field in the Web Content Management crawler configuration. Reducing this value might reduce some of the time that the crawler spends downloading content. 

The default value of the Time to wait between retrieval requests field is 2000 milliseconds. This means that the Web Content Management crawler waits for two seconds before it downloads content from the next URL in the list. Setting a wait time enforces politeness and helps prevent crawlers from rushing a specific server in a short amount of time. Even if content does not need to be downloaded, the crawler always waits for the specified time to pass. If you reduce the Time to wait between retrieval requests value, you can shorten this waiting time. This option can be effective when you need to crawl content from many URLs in the Web Content Management server. 

Keep the default value when you first configure the Web Content Management crawler so that you can determine how effectively the crawler works at that interval. After the initial crawl is finished, you can set the Time to wait between retrieval requests value to a smaller value, such as 100 milliseconds. You can set the value to 0 if the target Web Content Management server is powerful enough to accept continuous requests. 

Tuning other crawler configuration values, such as the Maximum number of active crawler threads or Maximum page size is usually not helpful. For more information about how configuring threads can influence crawler performance, see the technote, The meaning of "Maximum number of active crawler threads" in a Web Content Management crawler configuration [http://www.ibm.com/support/docview.wss?rs=63&uid=swg21383174]. 
Question 2:
Can the Web Content Management crawler crawl draft and expired content items in a Web Content Management server?

Answer 2: No. The seedlist servlet of the Web Content Management server does not generate links for draft and expired content items. The draft content must go through the workflow and approval process before it can be published. Expired content has expired for a reason and cannot be published externally. 
The Web Content Management crawler crawls the URLs that are found in the seed list; it cannot crawl URLs that are not published in the seed list.

Question 3:
Is it possible to configure the Web Content Management crawler to not crawl specific file formats such as PDF files to ensure that those types of files are not indexed?

Answer 3:
You cannot configure the Web Content Management crawler to exclude files of a specific format the way you can configure other crawlers, such as the Windows file system crawler. You can create a crawler plug-in and specify URL criteria to exclude certain URLs from the index. However, you cannot prevent the files that you want to exclude from being downloaded because the plug-in can change the content or metadata in documents only after they have been crawled.

Question 4:
Is it possible to configure the Web Content Management Crawler to crawl content that allows anonymous access and make that content available for search?

Answer 4:
It is not possible with one Web Content Management crawler. The Web Content Management crawler crawls what is published from the Web Content Management server.

One possible way to achieve this configuration is to use two crawlers:


 * Configure your Web Content Management server to have two libraries, one for secure access and one that allows access to all WebSphere Portal and anonymous users. 
 * Create two collections. Enable security in one collection for secure search. Do not enable security in the second collection so that non-secure search, or anonymous access, is permitted. 
 * Create a Web Content Management crawler in each collection. Configure one crawler to crawl secure content in the secure collection. Configure the second crawler to crawl public content in the non-secure collection to ensure that anonymous access in permitted.


For details, see WCM Allowing Anonymous Search through WebSphere Portal Search Center . If you need additional support, contact IBM Software Support for IBM Lotus Web Content Management. 

Question 5: 
The Web Content Management crawler stops when it is fetching a seed list page. It seems like it was unable to obtain the fully qualified host name. How can we avoid this problem? 

Answer 5: 
To avoid this problem, configure the Web Content Management server and ensure that the WCM_HOME environment variable specifies the fully qualified domain name. 

Question 6: 
We would like to add a metadata with a crawler plug-in, and would like to extract the metadata value from the WCM seedlist content itself. Is it possible to do that? 

Answer 6: 
As you think, you can add or replace any metadata by the crawler plug-in, but you can not use the WCM seedlist content itself as a value of the metadata. In the crawler plug-in, you can utilize the document URI by com.ibm.es.crawler.plugin.CrawledData#getURI() or document content itself(if it's not binary) by com.ibm.es.crawler.plugin.CrawledData#getOriginalContent() , but the crawler plug-in API does not extract the seedlist content itself. Thus you can not use the seedlist content itself. 

Question 7: 
We do not want to crawl the attachment to the file resource components, thus set SearchService.SearchSeed.ExcludeFileAttachments=true in wp_profile_root /PortalServer/wcm/shared/app/config/wcmservices/SearchService.properties file, as described in Configuring Web Content Management search options in the related information. 

However, the Web Content Management crawler continues to crawl the attachment. Why is this occurring? 

Answer 7: 
The Web Content Management follows the hyper link in the document if the target of the hyper link is still within the crawler scope. Thus this is working as expected. 

Note that there is no casual way to configure the Web Content Management crawler not to collect attached files. A work around is writing a crawler plugin to eliminate attached files. However, note that still the attachment will be downloaded by the Web Content Management crawler when you eliminate the attachment by the crawler plug-in, thus this work around will not reduce the overall crawling time. 

RELATED INFORMATION
#Crawler plug-ins [http://publib.boulder.ibm.com/infocenter/discover/v8r5m0/index.jsp?topic=/com.ibm.discovery.es.ap.doc/developing/iiyspplugovr.htm]
Meaning of "Maximum number of active crawler threads" [http://www.ibm.com/support/docview.wss?rs=63&uid=swg21383174]
Documentation updates for OmniFind Enterprise Edition [http://www.ibm.com/support/docview.wss?rs=63&uid=swg21308220]
WCM Allowing Anonymous Search through WebSphere Portal [http://www-10.lotus.com/ldd/portalwiki.nsf/dx/wcm-allowing-anonymous-search-through-websphere-portal-search-center]
Configuring Web Content Management search options [http://publib.boulder.ibm.com/infocenter/wpdoc/v6r1/index.jsp?topic=/com.ibm.wp.ent.doc/wcm/wcm_config_search.html]