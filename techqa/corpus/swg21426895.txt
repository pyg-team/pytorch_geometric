Title: IBM After upgrading WebSphere MQ on AIX, performance decreases when sending
messages between different hosts - United States

Text:
performance bad slow channel tcp tcpip ack delays delayed nodelayack segment segments segmented perf nagle algorithm TCP_NODELAY TCP_NODELAYACK 32766 mqminfo TECHNOTE (TROUBLESHOOTING)

PROBLEM(ABSTRACT)
 After upgrading WebSphere MQ, to 6.0.2.6 or later on version 6 or 7.0.0.2 or later on version 7 performance decreases when sending messages between queue managers or between a client and a queue manager on different hosts. This performance delay is not apparent unless the message is segmented and the segment size is larger than 32766 bytes. 

CAUSE
The message segment size has changed to be 32766 as a result of APAR IZ28473 [http://www-01.ibm.com/support/docview.wss?uid=swg1IZ28473] included in v6.0.2.6 or later or v7.0.0.2 or later.

An analysis of the MQ traces revealed some significant delays. The delays were caused by the fact that the runmqchl channel process would write a portion of the message to the TCP send buffer (32766 bytes). Immediately after this point, it would attempt to write another segment of the message (a further 32766 bytes) using a TCP send call. However, this would fail and TCP would return EWOULDBLOCK suggesting that the TCP send buffer was full. The TCP send buffer in use by MQ is configured to be 32766 bytes in size, so there might be a slight delay whilst the TCP layer frees up some space in the buffer by sending more data down the wire. As this is a non-blocking socket, MQ would then enter a select call, waiting to be notified by TCP that the socket was once more available for writing. The delay between each send of 32766 bytes was mostly over 200ms in length, resulting in a maximum transfer rate of about 150k per second. 

The delay was found to NOT be within MQ itself but is due to the TCP layer. The TCP layer is preventing MQ from writing any more data to the socket until an ACK is returned for the last packet sent. This ACK in turn is delayed, due to the TCP delayed ack model in use on the receiver side.


RESOLVING THE PROBLEM
This problem can be addressed by setting TCP_NODELAYACK on both sides of the channel. If this is for a client to queue manager connection, it should be set on the client and queue manager. 


MQ v6.0.2.7 or later:
Set the environment variable 'MQ_SET_NODELAYACK' to a valid value, for example: MQ_SET_NODELAYACK=Y 
Ensure that the environment variable is set in a context where it will be picked up by the MQ processes. This option will be recognized by MQ releases 6.0.2.7 and onwards. 

MQ v7.0.1.0 or later:
Set the environment variable 'MQ_SET_NODELAYACK' to a valid value, for example: MQ_SET_NODELAYACK=Y 
Ensure that the environment variable is set in a context where it will be picked up by the MQ processes. This option will be recognized by MQ releases 7.0.1.0 and onwards. 
or
Set NODELAYACK flag in the TCP stanza of the qm.ini, mqclient.ini, or the registry depending on the environment. Examples:
In the qm.ini file or mqclient.ini, add an entry to the TCP stanza. If you do not have a TCP stanza, add one.
TCP:
NoDelayAck=Y 


RELATED INFORMATION
#MQ APAR IZ28473 [http://www.ibm.com/support/docview.wss?uid=swg1IZ28473]


 

PRODUCT ALIAS/SYNONYM
 WebSphere MQ WMQ