Title: IBM Best Practices on how to Manage message Tracking on server with heavy mail routing - United States

Text:
Message tracking TECHNOTE (TROUBLESHOOTING)

PROBLEM
MT Collector task can cause domino server to hang over times or degrade the performance of server. 

Servers with high amount of mail routing traffic can face these common issues :

1. Index related error on mtstore.nsf
2. MT Collector taking up more CPU and impacting server performance or causing Server hang issues
3. Server crash due to unresponsiveness of MT Collector task


Below errors can be at time on server console
[18940118:00002-00001] 06/01/2016 12:05:26 Error full text indexing document NT00000000 /local/notes3/ftindex/mtdata/mtstore.ft

If you take a manual NSD from server during time of issue you can see similar stack where MT Collector might be causing semaphore errors and utilizing high amount of CPU.

###################################
###### thread 2/3 :: mtc, pid=16056340, tid=44695793, ptid=515) ######
###################################
[1] 0x0900000000566068 _cond_wait_global(??, ??, ??) + 0x268
[2] 0x0900000000566e74 _cond_wait(??, ??, ??) + 0x34
[3] 0x09000000005677e0 pthread_cond_timedwait(??, ??, ??) + 0x200
[4] 0x09000000009add2c WaitForThreadSem(0x30700000307, 0x1f4000001f4)
+ 0x10c
[5] 0x09000000009b64e4 WaitOnNativeSemaphore(0x307000000000307, 0x0,
0x1f4000001f4, 0x0) + 0xc4
[6] 0x09000000009b543c OSWaitEvent(0xa000000323ecf90, 0x1f4000001f4) +
0x15c
[7] 0x0900000000c85e74 AutoFDGCleanupThreadProc(0x0) + 0xb4
[8] 0x09000000009daf0c ThreadWrapper(0x0) + 0x14c
[9] 0x0900000000544e10 _pthread_body(??) + 0xf0
###################################
###### thread 3/3 :: mtc, pid=16056340, tid=56819857, ptid=258) ######
###################################
[1] 0x0900000000153bbc __fd_select(??, ??, ??, ??, ??) + 0xbc
[2] 0x0900000000c27e48 select(0x0, 0x0, 0x0, 0x0, 0x110036440) + 0x28
[3] 0x0900000000c27dbc unix_usleep(0x186a0000186a0) + 0x5c
[4] 0x09000000009d68ec OSDelayThread(0x6400000064) + 0x4c
[5] 0x0900000000c96158 FaultHandlerTask(0x0) + 0x438
[6] 0x0900000000544e10 _pthread_body(??) + 0xf0

Also in this cases you see below similar errors on console

++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++

LkMgr BEGIN Long Held Lock Dump ------------------
[0060:009E-2320] Lock(Mode=X * LockID(DB
DB=D:\IBM\Domino\Data2\mtdata\mtstore.nsf)) Waiters countNonIntentLocks
= 1 countIntentLocks = 0, queuLength = 1
[0060:009E-2320] Req(Status=Granted Mode=X Class=Manual Nest=0 Cnt=1
[0060:009E-2320] Tran=0 Func=N/A dbbktdsc.c:5202
[1E7C:0002-13D8])
[0060:009E-2320] rm_lkmgr_cpp:2125
[0060:009E-2320] rm_lkmgr_cpp:1358
[0060:009E-2320] nsfsem1_c:182
[0060:009E-2320] Req(Status=Waiting Mode=S Class=Manual Nest=0 Cnt=0
[0060:009E-2320] Tran=0 Func=N/A dbopen.c:4217 [048C:0002-1964]
Delay=1min)
[0060:009E-2320] rm_lkmgr_cpp:2125
[0060:009E-2320] rm_lkmgr_cpp:1358
[0060:009E-2320] nsfsem1_c:586
[0060:009E-2320] dbopen_c:862
[0060:009E-2320] LkMgr END Long Held Lock Dump ------------------


In such cases you may try to reindex the mtstore using the below command. 

tell mtc reindex 

If MTSTORE grows large in size that can cause these kind of error. Above command can give temporary relief . However issue may reprise once the mtstore again grows large in size over the time.


RESOLVING THE PROBLEM
If MTSTORE grows large in size that can cause these kind of error. Above command can give temporary relief . However issue 


may reprise once the mtstore again grows large in size.

In most cases if reindex and MTC compact does not resolve the issue the only option left is to recreate mtstore.nsf for which below steps can be followed:

1. Stop the router task and that will also quit the MT collector task
2. Now cut the existing mtdata folder from your data directory on server and move to some other place. 
3. Once the mtdata folder is moved, restart the task router and the mtdata directory will be recreated along with mtstore.nsf and other index files.

General questions that can come here:

Q1. "How MTC will update emails during the time when MTC task was down and router is still processing emails"
A. If you manually stop the MTC task, the router will keep updating the *.MTC Files in MTDATA directory.
So when the MTC tasks resumes back it should update all those entries into the mtstore.nsf back. So no data is being missed from being logged in mtstore.nsf



Q2. " If we recreate MTSTORE database, how the existing backed up mtstore database data can be used to track emails."
A. It is suggested to use any of your test server to achieve this. Follow below steps:

a) Install a test server and rename the default mtstore database.
b) Move mtdata folder from backup and place on test server.
c) Reindex the mtstore by giving command --> Tell MTC reindex
Note : before reindexing uncheck the Purge option in replication settings else all old data will get purged.
d) Then track messages and you should be able to get the logs.




Other Recommendations to avoid server performance issue or Message tracking issue while using message tracking with high amount of mail routing:

1. To improve performance of the full text index, the index should be periodically rebuilt. If the Admin believes a daily reindex is necessary they may set the following INI: MTCCompactReIndex=1 
2. If a different schedule is needed, an Admin can periodically schedule a Program document to reindex by executing a Tell command as shown here: -c tell mtc reindex

3. Your current mtstore.nsf is huge and this might be inefficient while the database is updated with new entries. 

It is suggested to purge documents not modified in more than 30 days which should reduce the size of mtstore.nsf

Console command : tell MTC purge value
where value is the maximum number of days to retain documents in the Mail Tracker Store database. The MTC task removes all documents older than value from the database. 


Over time large MTSTORE.nsf files are seen to cause high CPU usage by MT Collector task and in some scenarios also hang the server or cause it to crash.


This kind of issues generally happen with servers on which there is huge flow of Email traffic that over the time causes increase in size of MTSTORE and the MT Collector task is slowed down.

When default maintaiennce on MTSTORE runs in night it purges old data depending on the setting defined in database.
[/support/docview.wss?uid=swg21989997&aid=1] [/support/docview.wss?uid=swg21989997&aid=1]

While the documents gets purged, the white space will not be recovered. This leads to huge growth in size of MTSTORE with white space. Please see sample below.

[/support/docview.wss?uid=swg21989997&amp;aid=2]

As seen above the actual size of documents used space is just 5.9% and around 95% is the white space.

This has been found to be reason for old documents not getting purged from mtstore and further index related error. In some cases it has been also found that the manual Updall -R for such databases does not purge old documents.

In such cases it is found that Tell MTC Compact will not help recover unused space. You have to run Manual "compact -B" on mtstore to recover unused space.

So it is highly suggested that servers having high message flow with message tracking enabled, should have "Compact -B" run on mtstore.nsf atleast once a month.

Generally restarting server or router task gives temporary relief to server performance issue or Hang issue arising due to MTSTORE or other index related error on MTSTORE.nsf. 

However the core issue lies due to increase in database size of mtstore.nsf and unused space not being recovered.

Below steps can be followed to run maintainence on MTSTORE.nsf atleast once a month:

tell MTC quit
load compact -B mtstore.nsf
<wait till compact complete>
load MTC

It is suggested to first evaluate how long will it take for compact to complete.
And accordingly you can have scheduled program document for above commands to be run on scheduled basis.

Post having above maintainence in place for server with heavy Mail routing traffic it has been found that Message Tracking performance has been considerably improved and further the index related issue or server performance or hang issues caused by MT Collector task are not longer seen.