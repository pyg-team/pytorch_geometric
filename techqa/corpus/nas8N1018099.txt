Title: IBM Moving Data from DB2 for MVS to DB2 for OS/400 - United States

Text:
 TECHNOTE (TROUBLESHOOTING)

PROBLEM(ABSTRACT)
 This document describes the methods of moving data. 

RESOLVING THE PROBLEM
This document describes the methods that can be used to move data from DB2 for MVS (DB2/MVS) to DB2 for OS/400 (DB2/400). The first method discusses DRDA but does not explain how to configure DRDA. The second method is exporting and importing. 

1 DRDA (Distributed Relational Database Architecture)

DRDA is the easiest method for moving data between platforms but because it uses communications, it may not provide acceptable performance for large files. The second method is better suited for handling large files depending on the media used.

There are several options for using DRDA to move the data. One example requires product 5722ST1 and one example does not:

o Use Interactive SQL (Requires program product 5722ST1 )

The created file has the correct file format and records. DSPFFD can be used to verify the record format for the file.

-- STRSQL COMMIT(*CHG)
-- RELEASE ALL
-- COMMIT
-- CONNECT TO remote_db
-- F13 - Services
-- 1 - Change session attributes

o Specify SELECT output as 3 - File
o Specify the desired file and library on Output file
o Specify Option as 1 - Create file
o Press the Enter key

-- Press the Enter key
-- Type the desired SQL statement to select records from the remote file; for example, SELECT * FROM remote_file_name retrieves all records.

o Use Query Management/400 (does not require program product 5722ST1)

-- CRTSRCPF library/QQMQRYSRC RCDLEN(80)
-- WRKMBRPDM library/QQMQRYSRC
-- Press F6, Create

o Specify Source member as SELECT
o Specify Source type as TXT
o Press the Enter key
o Type an SQL statement to select the desired records from the remote file; for example, use the following statement: [/support/docview.wss?uid=nas8N1018099&amp;aid=1] Columns . . . : 1 68 Edit 
SEU==> 
FMT ** ...+... 1 ...+... 2 ...+... 3 ...+... 4 ...+... 5 ...+... 6 ...+...
*************** Beginning of data **********************************
''''''' SELECT * FROM remote_file_name 
''''''' 

o Press the Enter key
o Press F3 to exit edit mode
o Press the Enter key to accept the default exit options

To create an object by the name of SELECT in the specified library from the source member created above, on the OS/400 command line type the following:

CRTQMQRY QMQRY(library/SELECT) +
SRCFILE(library/QQMQRYSRC)

Press the Enter key. Run the previously created object by connecting to the remote database, running the SQL statement, creating the new database file on the local system, and adding the returned records to the file. On the OS/400 command line, type the following:

STRQMQRY QMQRY(library/SELECT) OUTPUT(*OUTFILE) +
OUTFILE(library/new_file) RDB(remote_db) RDBCNNMTH(*RUW)

Press the Enter key. 2 Export and Import

While this method has more steps than the DRDA method, it can be useful when moving large amounts of data or an entire database network. The primary steps include replicating the database and moving the data.

o Replicating the Database

The idea behind this step is to duplicate the empty database structure(s) on OS/400. No data is moved in this step. For example, if an entire schema (collection and all SQL objects within) is moved, the entire schema must be created on OS/400.

While the equivalent database structures can be created on OS/400 using CL commands or SQL, the easiest method for replicating the database structures on OS/400 is to use the original SQL DDL (Data Definition statements) from DB2 for MVS. To do this, get the SQL statements to OS/400 and into a source physical file member. Edit the file to ensure that each statement ends with a semi-colon. Once this is done, use the RUNSQLSTM command supplied with the SQL product, 5716ST1 or 5763ST1, to run the statements in the member and create the database environment. Here is an example source member and the command used to process the member:

FMT ** ...+... 1 ...+... 2 ...+... 3 ...+... 4 ...+... 5 ...+... 6 ...+... 7 ...+... 8 
*************** Beginning of data ***********************************************
0001.00 CREATE COLLECTION KLC; 
0002.00 CREATE TABLE KLC/TESTTABLE (FIELD1 CHARACTER (5) NOT NULL WITH 
0003.00 DEFAULT, FIELD2 INTEGER NOT NULL WITH DEFAULT); 
****************** End of data ************************************************** [/support/docview.wss?uid=nas8N1018099&amp;aid=1] RUNSQLSTM SRCFILE(library/source_file) SRCMBR(member) +
COMMIT(*NONE) NAMING(*SYS)

If using the original SQL DDL from DB2 for MVS is not possible, OS/400 CL commands or SQL can be used to manually create the database structures. For example, DDS can be used to create an externally described file that is equivalent to the one that would be created by SQL. Or, Interactive SQL or Query Management/400 can be used to run the SQL statements one at a time to create the required database environment. The desired result is that the new database environment matches the original on DB2 for MVS. (For example, the field attributes, such as null capable, length, data type, and so on, must match.)

o Move the Data

The OS/400 CPYF function is compatible with the data created by the DB2 unload function DSNTIAUL. Therefore, these are the functions that are used to export and import the data.

-- Export

Use the DSNTIAUL utility on DB2 for MVS to extract the data.

-- Data Transfer

Once the data has been exported, you must use some method to get it to OS/400. There are many methods available. Some items to consider are transfer speed, frequency of the transfer, and media compatibility. For example, a common tape media can be used to initially transfer large amounts of data, then Data Propagator can be used to keep the databases synchronized.

-- Import

The first step of the import is to transfer the data from the media into a flat (program-described) file on OS/400. The record length of the flat file should match that of the DB2 exported file, the file on the media. At this point the record length of the exported file may or may not match the record length of the replicated database table. If the replicated table has null capable fields, then the record length of the exported file should be one byte longer for each NULL capable field in the replicated table. However, if there are no NULL capable fields in the replicated table, then the record length of the exported file and the replicated table should match. Here is the process used to transfer the data from the media into a flat file:

o Create a program-described physical file with a record length matching that of the exported data. On the OS/400 command line, type the following:

CRTPF FILE(library/TEMP) RCDLEN(length_of_export)

Press the Enter key.

o Create a tape file with attributes that describe how the data was written to tape. On the OS/400 command line, type the following: 

CRTTAPF FILE(library/TAPF) DEV(TAP01) VOL(DATA) REELS(*SL)

Press the Enter key.

o Copy the data from tape into the program-described file. On the OS/400 command line, type the following: 

CPYFRMTAP FROMFILE(library/TAPF) TOFILE(library/TEMP) MBROPT(*ADD)

Press the Enter key. [/support/docview.wss?uid=nas8N1018099&amp;aid=1] The second step in the import is to copy the data from the program-described file to the replicated table. During this step, the system copies the records, mark fields as null, and converts floating point fields. Here is the command that can be used if the target table has both null capable fields and floating point fields. On the OS/400 command line, type the following:

CPYF FROMFILE(LIBRARY/TEMP) TOFILE(COLLECTION/TARGET) +
MBROPT(*ADD) FMTOPT(*NULLFLAGS *CVTFLOAT)

Press the Enter key.

If the target table does not have null capable fields, omit *NULLFLAGS. If the target table does not have floating point data, omit *CVTFLOAT.

After the copy is done, check the job log for errors using DSPJOBLOG. You should see that all of the records were copied and no indication of truncation or data mapping errors. If everything looks correct, the last step should be to validate the data in the replicated table.

Note: detailed assistance with these procedures is beyond the scope of Supportline.  


Cross reference information Segment Product Component Platform Version Edition Operating System IBM i 7.1 Operating System IBM i 6.1 
HISTORICAL NUMBER
 155781097