import argparse
import os
import os.path as osp
import tempfile
import time

import cupy
import psutil
import rmm
import torch
from rmm.allocators.cupy import rmm_cupy_allocator
from rmm.allocators.torch import rmm_torch_allocator

# Must change allocators immediately upon import
# or else other imports will cause memory to be
# allocated and prevent changing the allocator
# rmm.reinitialize() provides an easy way to initialize RMM
# with specific memory resource options across multiple devices.
# See help(rmm.reinitialize) for full details.
rmm.reinitialize(devices=[0], pool_allocator=True, managed_memory=True)
cupy.cuda.set_allocator(rmm_cupy_allocator)
torch.cuda.memory.change_current_allocator(rmm_torch_allocator)

import cudf  # noqa
import cugraph_pyg  # noqa
import torch.nn.functional as F  # noqa
# Enable cudf spilling to save gpu memory
from cugraph_pyg.loader import NeighborLoader  # noqa
from ogb.nodeproppred import PygNodePropPredDataset  # noqa
from tqdm import tqdm  # noqa

import torch_geometric  # noqa
from torch_geometric.utils import to_undirected  # noqa

cudf.set_option("spill", True)


def arg_parse():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter, )
    parser.add_argument(
        '--dataset',
        type=str,
        default='ogbn-papers100M',
        choices=['ogbn-papers100M', 'ogbn-products', 'ogbn-arxiv'],
        help='Dataset name.',
    )
    parser.add_argument(
        '--dataset_dir',
        type=str,
        default='/workspace/data',
        help='Root directory of dataset.',
    )
    parser.add_argument(
        "--dataset_subdir",
        type=str,
        default="ogb-papers100M",
        help="directory of dataset.",
    )
    parser.add_argument('-e', '--epochs', type=int, default=10)
    parser.add_argument('--num_layers', type=int, default=3)
    parser.add_argument('-b', '--batch_size', type=int, default=1024)
    parser.add_argument('--fan_out', type=int, default=10)
    parser.add_argument('--hidden_channels', type=int, default=256)
    parser.add_argument('--lr', type=float, default=0.003)
    parser.add_argument('--wd', type=float, default=0.0,
                        help='weight decay for the optimizer')
    parser.add_argument('--dropout', type=float, default=0.5)
    parser.add_argument('--num_workers', type=int, default=12)
    parser.add_argument(
        '--use_directed_graph',
        action='store_true',
        help='Whether or not to use directed graph',
    )
    parser.add_argument(
        "--model",
        type=str,
        default='SAGE',
        choices=['SAGE', 'GAT', 'GCN'],
        help="Model used for training, default GraphSAGE",
    )
    parser.add_argument(
        "--num_gat_conv_heads",
        type=int,
        default=4,
        help="If using GATConv, number of attention heads to use",
    )
    parser.add_argument('--tempdir_root', type=str, default=None)
    args = parser.parse_args()

    return args


def create_loader(
    data,
    num_neighbors,
    input_nodes,
    replace,
    batch_size,
    samples_dir,
    stage_name,
    shuffle=False,
):
    directory = osp.join(samples_dir, stage_name)
    os.mkdir(directory)
    return NeighborLoader(
        data,
        num_neighbors=num_neighbors,
        input_nodes=input_nodes,
        replace=replace,
        batch_size=batch_size,
        directory=directory,
        shuffle=shuffle,
    )


def train(model, train_loader):
    model.train()

    total_loss = total_correct = total_examples = 0
    for i, batch in enumerate(train_loader):
        batch = batch.cuda()
        optimizer.zero_grad()
        out = model(batch.x, batch.edge_index)[:batch.batch_size]
        y = batch.y[:batch.batch_size].view(-1).to(torch.long)
        loss = F.cross_entropy(out, y)
        loss.backward()
        optimizer.step()

        total_loss += loss * y.size(0)
        total_correct += out.argmax(dim=-1).eq(y).sum()
        total_examples += y.size(0)

    return total_loss.item() / total_examples, total_correct.item(
    ) / total_examples


@torch.no_grad()
def test(model, loader):
    model.eval()

    total_correct = total_examples = 0
    for batch in loader:
        batch = batch.cuda()
        out = model(batch.x, batch.edge_index)[:batch.batch_size]
        y = batch.y[:batch.batch_size].view(-1).to(torch.long)

        total_correct += out.argmax(dim=-1).eq(y).sum()
        total_examples += y.size(0)

    return total_correct.item() / total_examples


if __name__ == '__main__':
    args = arg_parse()
    if "papers" in str(args.dataset) and (psutil.virtual_memory().total /
                                          (1024**3)) < 390:
        print("Warning: may not have enough RAM to use this many GPUs.")
        print("Consider upgrading RAM if an error occurs.")
        print("Estimated RAM Needed: ~390GB.")
    wall_clock_start = time.perf_counter()

    root = osp.join(args.dataset_dir, args.dataset_subdir)
    print('The root is: ', root)
    dataset = PygNodePropPredDataset(name=args.dataset, root=root)
    split_idx = dataset.get_idx_split()

    data = dataset[0]
    if not args.use_directed_graph:
        data.edge_index = to_undirected(data.edge_index, reduce="mean")

    graph_store = cugraph_pyg.data.GraphStore()
    graph_store[dict(
        edge_type=('node', 'rel', 'node'),
        layout='coo',
        is_sorted=False,
        size=(data.num_nodes, data.num_nodes),
    )] = data.edge_index

    feature_store = cugraph_pyg.data.TensorDictFeatureStore()
    feature_store['node', 'x'] = data.x
    feature_store['node', 'y'] = data.y

    data = (feature_store, graph_store)

    if args.model == "GAT":
        print(f"Training {args.dataset} with GAT model.")
        model = torch_geometric.nn.models.GAT(
            dataset.num_features, args.hidden_channels, args.num_layers,
            dataset.num_classes, heads=args.num_gat_conv_heads).cuda()
    elif args.model == "GCN":
        print(f"Training {args.dataset} with GCN model.")
        model = torch_geometric.nn.models.GCN(
            dataset.num_features,
            args.hidden_channels,
            args.num_layers,
            dataset.num_classes,
        ).cuda()
    elif args.model == "SAGE":
        print(f"Training {args.dataset} with GraphSAGE model.")
        model = torch_geometric.nn.models.GraphSAGE(
            dataset.num_features,
            args.hidden_channels,
            args.num_layers,
            dataset.num_classes,
        ).cuda()
    else:
        raise ValueError('Unsupported model type: {args.model}')

    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,
                                 weight_decay=args.wd)

    with tempfile.TemporaryDirectory(dir=args.tempdir_root) as samples_dir:
        loader_kwargs = dict(
            data=data,
            num_neighbors=[args.fan_out] * args.num_layers,
            replace=False,
            batch_size=args.batch_size,
            samples_dir=samples_dir,
        )

        train_loader = create_loader(
            input_nodes=split_idx['train'],
            stage_name='train',
            shuffle=True,
            **loader_kwargs,
        )

        val_loader = create_loader(
            input_nodes=split_idx['valid'],
            stage_name='val',
            **loader_kwargs,
        )

        test_loader = create_loader(
            input_nodes=split_idx['test'],
            stage_name='test',
            **loader_kwargs,
        )
        prep_time = round(time.perf_counter() - wall_clock_start, 2)
        print("Total time before training begins (prep_time) =", prep_time,
              "seconds")
        print("Beginning training...")
        val_accs = []
        times = []
        train_times = []
        inference_times = []
        best_val = 0.
        start = time.perf_counter()
        epochs = args.epochs
        for epoch in range(1, epochs + 1):
            train_start = time.perf_counter()
            loss, train_acc = train(model, train_loader)
            train_end = time.perf_counter()
            train_times.append(train_end - train_start)
            inference_start = time.perf_counter()
            train_acc = test(model, train_loader)
            val_acc = test(model, val_loader)

            inference_times.append(time.perf_counter() - inference_start)
            val_accs.append(val_acc)
            print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train:'
                  f' {train_acc:.4f} Time: {train_end - train_start:.4f}s')
            print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, ')

            times.append(time.perf_counter() - train_start)
            if val_acc > best_val:
                best_val = val_acc

        print(f"Total time used: is {time.perf_counter()-start:.4f}")
        val_acc = torch.tensor(val_accs)
        print('============================')
        print("Average Epoch Time on training: {:.4f}".format(
            torch.tensor(train_times).mean()))
        print("Average Epoch Time on inference: {:.4f}".format(
            torch.tensor(inference_times).mean()))
        print(f"Average Epoch Time: {torch.tensor(times).mean():.4f}")
        print(f"Median time per epoch: {torch.tensor(times).median():.4f}s")
        print(f'Final Validation: {val_acc.mean():.4f} Â± {val_acc.std():.4f}')
        print(f"Best validation accuracy: {best_val:.4f}")

        print("Testing...")
        final_test_acc = test(model, test_loader)
        print(f'Test Accuracy: {final_test_acc:.4f}')

    total_time = round(time.perf_counter() - wall_clock_start, 2)
    print("Total Program Runtime (total_time) =", total_time, "seconds")
